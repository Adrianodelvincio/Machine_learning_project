{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compatible-portfolio",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "project_dir = '../../'\n",
    "data_dir = project_dir + 'data/'\n",
    "\n",
    "import sys\n",
    "sys.path.append(project_dir + 'NN/')\n",
    "\n",
    "import numpy as np\n",
    "import importlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import MLP\n",
    "import layer\n",
    "importlib.reload(MLP)\n",
    "importlib.reload(layer)\n",
    "from MLP import MLP, MLP_w\n",
    "from utils.preprocessing import split,StandardScaler\n",
    "from utils.losses import MSE, MEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' FOR THE FIRST TIME\n",
    "raw_data=np.loadtxt(\"../../data/TR.csv\",delimiter=\",\")[:,1:]\n",
    "\n",
    "sort_idx = np.argsort(raw_data[:,11]) ; raw_data = raw_data[sort_idx]\n",
    "np.random.shuffle(raw_data)\n",
    "input_data=raw_data[:,:-2]\n",
    "input_labels=raw_data[:,-2:]\n",
    "\n",
    "frac_test=0.15\n",
    "data, test_set, labels, test_labels = split(input_data, input_labels, \n",
    "                                            kind=\"hold_out\",frac_training=1-frac_test)\n",
    "Test_dataset = np.column_stack((test_set,test_labels))\n",
    "Data_dataset = np.column_stack((data,labels))\n",
    "np.savetxt('../../data/Test_set.txt',Test_dataset) ; np.savetxt('../../data/Data_set.txt',Data_dataset)\n",
    "'''\n",
    "raw_data = np.loadtxt(\"../../data/Data_set.txt\")\n",
    "data_scaler = StandardScaler() ; labels_scaler = StandardScaler()\n",
    "raw_data[:,:-2] = data_scaler.fit_transform(raw_data[:,:-2]) \n",
    "raw_data[:,-2:] = labels_scaler.fit_transform(raw_data[:,-2:])\n",
    "\n",
    "#splitting the data from the labels\n",
    "data=raw_data[:,:-2]\n",
    "labels=raw_data[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e5203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xavier weight inizialization\n",
    "def xavier(structure):\n",
    "    start=np.zeros(len(structure))\n",
    "    for idx,num in enumerate(structure):\n",
    "        if idx==0:\n",
    "            start[idx]=np.sqrt(6)/np.sqrt(structure[idx])\n",
    "        else:\n",
    "            start[idx]=np.sqrt(6)/np.sqrt(structure[idx-1]+structure[idx])\n",
    "    return list(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93bec95b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e-07 3.16227766e-07 1.00000000e-06 3.16227766e-06\n",
      " 1.00000000e-05]\n"
     ]
    }
   ],
   "source": [
    "list_lamb = np.logspace(-7,-5,5)  ; print(list_lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neither-radius",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training 72 possible combinations\n",
      "[trained=72] [elaps t=575.9 s] [remain t =0.0 s]s]\n",
      "Time for the grid search: 575.8696660995483 s\n"
     ]
    }
   ],
   "source": [
    "import utils.grid_search\n",
    "importlib.reload(utils.grid_search)\n",
    "from utils.grid_search import grid_search\n",
    "\n",
    "# Structure to test: \n",
    "n_feat = np.shape(labels)[1]\n",
    "#model1 = {'structure':[10, n_feat], 'func':['tanh', 'linear'], 'starting_points': xavier([10, n_feat])}\n",
    "model1 = {'structure':[5,10, n_feat], 'func':[\"tanh\",'relu', 'linear'], 'starting_points': xavier([5,10, n_feat])}\n",
    "model2 = {'structure':[20,20,n_feat], 'func':['tanh','relu','linear'], 'starting_points': xavier([20,20, n_feat])}\n",
    "model3 = {'structure':[10,10,n_feat], 'func':['tanh','relu','linear'],'starting_points': xavier([10,10,n_feat])}\n",
    "#model5 = {'structure':[10,5,n_feat], 'func':['tanh','tanh','linear'],'starting_points': xavier([10,5,n_feat])}\n",
    "#model6 = {'structure':[10,10,n_feat], 'func':['tanh','tanh','linear'],'starting_points': xavier([10,10,n_feat])}\n",
    "\n",
    "models = [model1, model2, model3]#, model5, model6]\n",
    "dict_models = {f'Model{i}': m for i, m in enumerate(models)} \n",
    "\n",
    "list_eta = [5e-4]\n",
    "list_alpha = np.arange(0.1,0.3,0.1)\n",
    "list_lamb = np.logspace(-6,-5,4) ; list_beta = np.arange(0.7,0.9,0.1)\n",
    "dict_params = {'eta':list_eta, 'alpha':list_alpha, 'lamb':list_lamb, 'epoch':[10000], \n",
    "                'RMSProp' : [True], 'nesterov' : [True] , 'beta' : list_beta , 'verbose' : [False], 'batch_size' : [-1], 'error_threshold' : [0] ,'patience' : [200]}\n",
    "\n",
    "grid_results = grid_search(MLP_w, dict_models, dict_params, \n",
    "                           data, labels, MEE, n_jobs = -1,\n",
    "                           verbose = 1, kind = 'k_fold', k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clean-membrane",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'eta': 0.0005,\n",
       "  'alpha': 0.2,\n",
       "  'lamb': 2.1544346900318822e-06,\n",
       "  'epoch': 10000,\n",
       "  'RMSProp': True,\n",
       "  'nesterov': True,\n",
       "  'beta': 0.7999999999999999,\n",
       "  'verbose': False,\n",
       "  'batch_size': -1,\n",
       "  'error_threshold': 0,\n",
       "  'patience': 200},\n",
       " 'model': {'structure': [5, 10, 2],\n",
       "  'func': ['tanh', 'relu', 'linear'],\n",
       "  'starting_points': [1.0954451150103321,\n",
       "   0.6324555320336758,\n",
       "   0.7071067811865475]},\n",
       " 'model_name': 'Model0',\n",
       " 'Error': 0.2740324333500792}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_results[0]\n",
    "#np.savetxt('../../data/sigmoid_search.txt',grid_results[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d6519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comment after the grid search is ended\n",
    "import json\n",
    "\n",
    "with open('grid_search_pv2.json','w') as fp:\n",
    "    json.dump(grid_results,fp) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b3800e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../report/tanh_search.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27206/3784548662.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loading dictionary grid_search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../report/tanh_search.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgrid_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../report/tanh_search.json'"
     ]
    }
   ],
   "source": [
    "#loading dictionary grid_search\n",
    "with open('../report/tanh_search.json') as json_file:\n",
    "    grid_results = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac_training=0.8\n",
    "input_data, val_data, train_labels, val_labels=split(data, labels,kind=\"hold_out\",\n",
    "                                               frac_training=frac_training)\n",
    "best_model_dict = grid_results[0]\n",
    "best_model_dict['model']\n",
    "best_model = MLP(**best_model_dict['model'])\n",
    "train_dict = dict(best_model_dict['train'])\n",
    "#del train_dict['n_candidate']\n",
    "#del train_dict['test_more_init']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faa0878",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.train(input_data, train_labels, val_data, val_labels, **train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116dc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(network, input_data, val_data, labels, val_labels):\n",
    "    train_pred = network.predict(input_data)\n",
    "    val_pred = network.predict(val_data)\n",
    "    x = np.arange(len(network.train_MEE))\n",
    "\n",
    "    fig = plt.figure(figsize=(13,4))\n",
    "\n",
    "    fig.add_subplot(131)\n",
    "    plt.plot(x,network.train_MEE)\n",
    "    plt.plot(x,network.val_MEE,label=\"test\")\n",
    "    plt.title(\"Learning curve\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Squared error\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.legend()\n",
    "\n",
    "    fig.add_subplot(132)\n",
    "    plt.title('Residual for training data')\n",
    "    plt.plot(np.arange(len(labels)),labels[:,0]-train_pred[:,0],\".\",label=\"residual0\")\n",
    "    plt.plot(np.arange(len(labels)),labels[:,1]-train_pred[:,1],\".\",label=\"residual1\")\n",
    "    plt.legend()\n",
    "\n",
    "    fig.add_subplot(133)\n",
    "    plt.title('Residual for validation data')\n",
    "    plt.plot(np.arange(len(val_labels)),val_labels[:,0]-val_pred[:,0],\".\",label=\"residual0\")\n",
    "    plt.plot(np.arange(len(val_labels)),val_labels[:,1]-val_pred[:,1],\".\",label=\"residual1\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c294d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(best_model, input_data, val_data, train_labels, val_labels)\n",
    "pred = best_model.predict(data)\n",
    "plt.plot(labels[:,1],labels[:,0],\".\")\n",
    "plt.plot(pred[:,1],pred[:,0],\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074215d",
   "metadata": {},
   "source": [
    "## Testing PARALLEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e715effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.grid_search\n",
    "importlib.reload(utils.grid_search)\n",
    "from utils.grid_search import grid_search\n",
    "\n",
    "# Structure to test: \n",
    "n_feat = np.shape(labels)[1]\n",
    "model1 = {'structure':[10, n_feat], 'func':['sigmoid', 'linear'], 'starting_points': [0.5]*2}\n",
    "model2 = {'structure':[15, n_feat], 'func':['sigmoid', 'linear'], 'starting_points': [0.5]*2}\n",
    "model3 = {'structure':[20, n_feat], 'func':['sigmoid', 'linear'], 'starting_points': [0.5]*2}\n",
    "#model5= {'structure':[4,4, n_feat], 'func':['sigmoid','sigmoid','linear'], 'starting_points': [0.5]*2}\n",
    "#model4 = {'structure':[5,4,n_feat], 'func':['sigmoid','sigmoid','linear'],'starting_points': [0.5]*2}\n",
    "#model6 = {'structure':[6,6,n_feat], 'func':['sigmoid','sigmoid','linear'],'starting_points': [0.5]*2}\n",
    "models = [model1, model2, ]#model3, model4, model5, model6]\n",
    "dict_models = {f'Model{i}': m for i, m in enumerate(models)} \n",
    "\n",
    "list_eta = [1e-2,5e-3]\n",
    "list_alpha = [0., 1.]#np.arange(0,1, 0.5)\n",
    "list_lamb = [0.] # np.arange(0,1,0.5)\n",
    "list_beta = np.arange(0.6, 1, 0.1)\n",
    "\n",
    "dict_params = {'eta':list_eta, 'alpha':list_alpha, 'lamb':list_lamb, 'epoch':[1000], \n",
    "               'RMSProp' : [True], 'nesterov' : [False] , 'beta' : list_beta, 'verbose': [False] }\n",
    "\n",
    "grid_results = grid_search(MLP_w, dict_models, dict_params, \n",
    "                           data, labels, MEE,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1, kind = 'hold_out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80dfa2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "grid_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
